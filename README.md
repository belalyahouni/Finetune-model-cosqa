# Semantic Search Engine with Sentence Transformers & CoSQA Fine-Tuning
This project implements a semantic search engine that allows users to upload documents (PDF or text) and perform natural language searches a using fine-tuned model.

## Itâ€™s built using:
ğŸ§© SentenceTransformers for model training and embeddings

âš¡ FastAPI for serving the search API

ğŸ” Usearch for fast vector similarity retrieval

ğŸ“Š CoSQA dataset for model fine-tuning and evaluation

## ğŸš€ Overview
This project combines machine learning model fine-tuning with a search backend and API interface.

Workflow

Fine-tune a Sentence Transformer model on the CoSQA dataset (finetuning_multiple.py / part_3.ipynb)

Index documents (PDF or TXT) using FastAPI (main.py + search_engine.py)

Search semantically related text based on natural language queries

Evaluate the model using Recall@10, MRR@10, and nDCG@10 (evaluate.py, part_2.ipynb)


## ğŸ—ï¸ Project Structure

ğŸ“‚ ML-for-Context-in-AI-Assistant/

â”‚

â”œâ”€â”€ code

â”‚      â”œâ”€â”€finetuning_multiple.py     # Fine-tunes SentenceTransformer on CoSQA

â”‚      â”œâ”€â”€ search_engine.py           # Encodes, indexes, and retrieves documents

â”‚      â”œâ”€â”€ main.py                    # FastAPI backend for indexing/search endpoints

â”‚      â”œâ”€â”€evaluate.py                # Evaluation script (Recall, MRR, nDCG)

â”‚      â”‚

â”‚      â”œâ”€â”€ part_1.ipynb               # API demo: uploading and querying documents

â”‚      â”œâ”€â”€ part_2.ipynb               # Evaluation notebook for retrieval metrics

â”‚      â””â”€â”€ part_3.ipynb               # Full fine-tuning + evaluation pipeline

â”‚

â”œâ”€â”€ documents/                 # sample PDFs or text files (for part2.ipynb)

â”œâ”€â”€ README.md    

â”œâ”€â”€requirements.txt

â””â”€â”€ README.md 

## âš™ï¸ Installation
1. Clone the Repository

git clone https://github.com/belalyahouni/ML-for-Context-in-AI-Assistant

cd semantic-search-engine

3. Create and Activate a Virtual Environment

python -m venv venv

source venv/bin/activate

5. Install Dependencies

pip install -r requirements.txt

## Running the API

Start the FastAPI server:

This step will be needed for part1.ipynb.

You must be in the code repository.

uvicorn main:app --reload --port 8080

## ğŸ“¥ Index Documents

You can upload PDF or TXT files to build the search index.

## ğŸ” Search

Once documents are indexed, send a query.

## Evaluation

Evaluate retrieval performance on CoSQA:

evaluate_model(model_name)

Metrics reported:

Recall@10 â€“ how often a relevant doc appears in top 10

MRR@10 â€“ how high the first relevant doc ranks

nDCG@10 â€“ measures ranking quality considering all relevant docs

## Fine-tuning

fine_tune_cosqa()

This function:

Loads and preprocesses the dataset.

Creates query-document pairs.

Uses MultipleNegativesRankingLoss to fine-tune embeddings.

Logs and plots loss using the custom callback.

Outputs training logs and a loss graph for visualization.

## ğŸ§ª Notebooks Summary

Notebook	Purpose

part_1.ipynb	Client demo for uploading and searching documents using the API

part_2.ipynb	Evaluation of search quality using CoSQA metrics

part_3.ipynb	Full fine-tuning + evaluation experiment
